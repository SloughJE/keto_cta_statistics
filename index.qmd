---
# title: "KETO-CTA: 'Plaque begets plaque, ApoB does not'"
# subtitle: "The Statistics Cause Doubt"
author: "John Slough"
format:
  revealjs:
    self-contained: true
    theme: [night]
    slide-number: true
    
---

<div style="font-size: 200%; margin-top: 1.5em; text-align: center; font-weight: bold;">
[Plaque Begets Plaque, ApoB Does Not](https://www.jacc.org/doi/10.1016/j.jacadv.2025.101686)
</div>

<div style="margin-top: 1.2em; margin-bottom: 1.5em; text-align: center; font-weight: bold; font-size: 120%;">
The Statistics Cause Doubt
</div>

<hr style="width: 45%; margin: 2em auto 2em auto; border: 0.5px solid #888;">

<div style="text-align: center; font-size: 90%;">
John Slough
</div>


---

## Study Summary {.smaller}
[Plaque Begets Plaque, ApoB Does Not — Soto-Mota et al., 2025](https://www.jacc.org/doi/10.1016/j.jacadv.2025.101686)

- **Trial ID**: [NCT05733325](https://clinicaltrials.gov/study/NCT05733325)
<br>

- **Design**: 1-year prospective cohort using coronary CT angiography (CCTA)  
- **Participants**: 100 lean, metabolically healthy adults on keto ≥2 yrs  
  - LDL-C ≥190 mg/dL, HDL-C ≥60 mg/dL, TG ≤80 mg/dL, ApoB 185 ± 51 mg/dL  
  <br>
  
- **Findings**: No link between ApoB/LDL-C (baseline/change) and plaque progression  
- **Predictors**: Baseline plaque (CAC, NCPV, TPS, PAV) strongly predicted progression (ΔNCPV) 
- **Stats**: Bayesian analysis favored no ApoB–plaque link (6–10× vs alt)  
<br>
- **Conclusion**: *Plaque begets plaque; ApoB does not*  



---

<div style="font-size: 170%; line-height: 1.4;">
1. ΔNCPV as Outcome Variable  
2. Univariable Linear Models  
3. Bayesian Inference  
4. Bayesian Prior Choice  
5. Bayes Factor Interpretation  
</div>


# ΔNCPV as Outcome Variable
**Plaque begets plaque**: biology or mathematical artifact?


## 1 ΔNCPV as Outcome Variable {.smaller}

> "All baseline plaque metrics (coronary artery calcium, NCPV, total plaque score, and percent atheroma volume) were strongly associated with the **change in NCPV**."

Change in noncalcified plaque volume $\Delta \text{NCPV}$ was the outcome:

$$
\Delta \text{NCPV} = \text{NCPV}_{1} - \text{NCPV}_0
$$

They regressed $\Delta \text{NCPV}$ directly on its baseline value $\text{NCPV}_0$:  

$$
\Delta \text{NCPV} = \alpha + \beta \, \text{NCPV}_0 + \varepsilon
$$

But this introduces **mathematical coupling**, because $\text{NCPV}_0$ appears on both sides of the equation:

$$
\text{NCPV}_{1} - \text{NCPV}_0 = \alpha + \beta \, \text{NCPV}_0 + \varepsilon
$$

---

## 1 ΔNCPV as Outcome Variable {.smaller}

<div style="font-size: 75%; line-height: 1.3;">

["Mathematical coupling occurs when one variable directly or indirectly contains the whole or part of another, and the two variables are then analysed using correlation or regression. As a result, the statistical procedure of testing the null hypothesis — that the coefficient of correlation or the slope of regression is zero — might no longer be appropriate"](https://pubmed.ncbi.nlm.nih.gov/16526009/)

</div>

<br>
<div style="font-size: 80%; line-height: 1.3;">

Regression model: $\text{NCPV}_{1} - \text{NCPV}_0 = \alpha + \beta \, \text{NCPV}_0 + \varepsilon$

<br>
The regression coefficient (slope): $\beta = \frac{\operatorname{Cov}((\text{NCPV}_1 - \text{NCPV}_0),\ \text{NCPV}_0)}{\operatorname{Var}(\text{NCPV}_0)} = \frac{\operatorname{Cov}(\Delta \text{NCPV},\ \text{NCPV}_0)}{\operatorname{Var}(\text{NCPV}_0)}$  

<br>
This simplifies to: $\beta = \frac{\rho\, \sigma_1 - \sigma_0}{\sigma_0}$  

where:

- $\rho = \operatorname{Cor}(\text{NCPV}_0,\ \text{NCPV}_1)$  
- $\sigma_0$, $\sigma_1$ = SDs at baseline and follow-up
</div>

<div style="font-size: 80%; line-height: 1.3;">

With baseline NCPV contributing to both predictor and outcome, the slope captures an **inseparable combination** of mathematical coupling and possible biological change. <br>
It is not a clean estimate of baseline influence.
</div>



---

## 1 ΔNCPV as Outcome Variable {.smaller}

From Oldham* (1962): $\beta > 0 \quad\text{if}\quad \rho > \frac{\sigma_0}{\sigma_1}$

The slope depends on:

- **correlation** between baseline and follow-up ($\rho$)
- **relative spread** of the two time points

So a positive or negative slope arises **purely from the math**.

In this study:

- Almost all participants had increased NCPV
- Implies $\rho$ was moderate-to-high, and $\sigma_1 > \sigma_0$

These conditions tend to bias the slope upward; whether the resulting positive association reflects biology, coupling, or both cannot be determined from this model.

<small>\*Source: [Oldham, 1962](https://www.sciencedirect.com/science/article/abs/pii/0021968162901169), *J. Chronic Dis.*</small>

---

## 1 ΔNCPV as Outcome Variable {.smaller}

```r
n <- 100 # Set the number of values to generate
ncpv_0 <- rnorm(n, mean = 100, sd = 10) # Create 100 random numbers centered around 100
ncpv_1 <- rnorm(n, mean = 110, sd = 10) # Create another 100 random numbers, centered around 110  
delta_ncpv <- ncpv_1 - ncpv_0 # Subtract the first set from the second to get the difference

```
<br>

::: columns

::: {.column width="50%"}

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap="No true association"}

library(ggplot2)
library(plotly)

set.seed(42)

n <- 100
ncpv_0 <- rnorm(n, mean = 100, sd = 10)
ncpv_1 <- rnorm(n, mean = 120, sd = 10)
delta_ncpv <- ncpv_1 - ncpv_0

df <- data.frame(
  NCPV_0 = ncpv_0,
  NCPV_1 = ncpv_1,
  Delta_NCPV = delta_ncpv
)

model_raw <- lm(NCPV_1 ~ NCPV_0, data = df)
slope_raw <- coef(model_raw)[2]
pval_raw <- summary(model_raw)$coefficients[2, 4]
pval_raw_text <- format.pval(pval_raw, eps = 0.001)
label_raw <- sprintf("β = %.2f, p %s", slope_raw, pval_raw_text)

p_raw = ggplot(df, aes(x = NCPV_0, y = NCPV_1)) +
  geom_point(alpha = 0.7, size = 2.5) +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue") +
  annotate("text", x = min(df$NCPV_0) + 30, y = max(df$NCPV_1),
           label = label_raw, color = "darkred", hjust = 0, size = 4) +
  labs(
    title = "Basline vs Follow-up",
    subtitle = "Two independent variables — no true effect",
    x = "Baseline NCPV",
    y = "Follow up NCPV"
  ) +
  theme_minimal()

ggplotly(p_raw, height = 350, width = 500) %>%
  config(displayModeBar = FALSE) 

```
:::

::: {.column width="50%" .fragment}

```{r echo=FALSE, message=FALSE, warning=FALSE, fig.cap="Association due to mathematical coupling"}


model_change <- lm(Delta_NCPV ~ NCPV_0, data = df)
slope_change <- coef(model_change)[2]
pval_change <- summary(model_change)$coefficients[2, 4]
pval_change_text <- format.pval(pval_change, eps = 0.001)
label_change <- sprintf("β = %.2f, p %s", slope_change, pval_change_text)


p = ggplot(df, aes(x = NCPV_0, y = Delta_NCPV)) +
  geom_point(alpha = 0.7, size = 2.5) +
  geom_smooth(method = "lm", se = FALSE, color = "steelblue") +
  annotate("text", x = min(df$NCPV_0) + 30, y = max(df$Delta_NCPV),
           label = label_change, color = "darkred", hjust = 0, size = 4) +
  labs(
    title = "Basline vs Change in NCPV",
    subtitle = "Mathematical Coupling Creates a Spurious Slope",
    x = "Baseline NCPV",
    y = "Change in NCPV (ΔNCPV)"
  ) +
  theme_minimal()

ggplotly(p, height = 350, width = 500) %>%
  config(displayModeBar = FALSE)

```

:::

:::


---

## 1 ΔNCPV as Outcome Variable {.smaller}


An alternative is to model NCPV at follow-up ($\text{NCPV}_1$) directly while adjusting for baseline NCPV. This example uses ApoB as the independent variable:

$$
\text{NCPV}_1 = \alpha + \gamma\,\text{NCPV}_0 + \beta ApoB + \varepsilon
$$

This approach avoids mathematical coupling, reduces residual variance, and allows the coefficient on $ApoB$ to reflect biological association — not algebraic structure.


<br>


You could test whether baseline NCPV predicts follow-up using a mixed-effects model with a Time × Baseline interaction:

> $$
> \text{NCPV}_{ij} = \alpha + \gamma\,\text{Time}_{ij} + \beta\,\text{NCPV}_{0j} + \delta\,(\text{Time}_{ij} \cdot \text{NCPV}_{0j}) + b_j + \varepsilon_{ij}
> $$

but the with the number of subjects this must be done carefully.


---

## 1 ΔNCPV as Outcome Variable {.smaller}

<div style="font-size: 80%; line-height: 0.8;">
You cannot determine whether a positive or negative slope from ΔNCPV ∼ NCPV₀ reflects biology or math, because the math builds the relationship.
To isolate biological effects, you must model follow-up directly with baseline as a covariate — not as part of the outcome.

<br>

["Statisticians have repeatedly warned against correlating/regressing change with baseline due to two methodological concerns known as mathematical coupling and regression to the mean."](https://pubmed.ncbi.nlm.nih.gov/16526009/)

["Mathematical coupling can lead to an artificially inflated association between initial value and change score when correlation or regression is used."](https://www.sciencedirect.com/science/article/abs/pii/S0895435609003497#:~:text=Mathematical%20coupling%20occurs%20%E2%80%9Cwhen%20one%20variable%20directly,posttreatment%20score%2C%20they%20contain%20the%20pretreatment%20score.)
</div>

<br>
<br>
**Plaque begets plaque**: biology or a mathematical artifact?


<br>
<br>
<div style="font-size: 50%; margin-top: 1em;">

**See also:**  
[Analysis of 'change scores'](https://clok.uclan.ac.uk/38260/1/38260%20dyab050.pdf)  
[Assessing the Relationship between the Baseline Value of a Continuous Variable and Subsequent Change Over Time](https://pmc.ncbi.nlm.nih.gov/articles/PMC3854983/)  
[Mathematic coupling of data: a common source of error](https://pmc.ncbi.nlm.nih.gov/articles/PMC1345065/)
[Revisiting the relation between change and initial value: a review and evaluation](https://onlinelibrary.wiley.com/doi/10.1002/sim.2538)

</div>


# Univariable Linear Models
At best: exploratory. 

At worst: misleading.

## 2 Univariable Linear Models {.smaller}

> "Linear models on the primary (NCPV) and secondary outcomes were **univariable**"

Despite having multiple baseline predictors available  
(age, sex, ApoB, Δ-ApoB, CAC, NCPV₀, LDL-C exposure),  
each was tested separately in single-predictor regressions.

This modeling choice introduces **omitted-variable bias**:  

> "...omitting a relevant variable from a model which explains the independent and dependent variable leads to biased estimates."  
> [Wilms (2021)](https://www.researchgate.net/publication/354514325_Omitted_variable_bias_A_threat_to_estimating_causal_relationships)

When a predictor is correlated with both the outcome and another omitted variable, its coefficient may absorb the effect of that omitted factor.

---

## 2 Univariable Linear Models {.smaller}

#### Example: ΔNCPV, ApoB and Age 

They modeled:

$$
\Delta \text{NCPV} = \alpha + \beta \cdot \text{ApoB} + \varepsilon
$$

But if **age** also predicts ΔNCPV and correlates with ApoB, then $\beta$ is **biased** — it partly reflects the effect of age.


A more appropriate model would be:

$$
\Delta \text{NCPV} = \alpha + \beta_1 \cdot \text{ApoB} + \beta_2 \cdot \text{Age} + \varepsilon
$$

This separates the contribution of ApoB from that of age.

<br>
Univariable Linear Models are make confounding almost certain, especially in small, non-randomized human data, undermining any claim of association or non-association.

Univariable Linear Models are exploratory and can be misleading. 



## 2 Univariable Linear Models {.smaller}

But wait:
<div style="font-size: 75%; margin-top: 1em;">
> "Estimated lifetime LDL-C exposure was only a significant predictor of final NCPV in the univariable analysis but lost significance when age was included as a covariate. Both age and lifetime LDL-C exposure lost significance when baseline CAC was included in the model."
</div>

So they **did use multivariable models**! — but only on the follow-up NCPV, not for ΔNCPV, the paper's main endpoint?

This selective use raises questions:

<ul style="margin-top: 0; margin-bottom: 0; line-height: 0.85;">
  <li>Why not model ΔNCPV with adjustment for known confounders?</li>
  <li>Why apply different modeling rules depending on the predictor?</li>
  <li>Why include some adjusted models in the paper?</li>
</ul>


Were multivariable models used selectively for some reason? And why not on the study's main endpoint?


# Bayesian Modeling 
Unusual. Fragile. Overstated.


## 3 Bayesian Inference {.smaller}

> "Bayesian inference adds credence to finding that there is no association between NCPV vs LDL-C or ApoB..."

The authors used Bayesian inference to support their finding that **ApoB has no association with plaque progression**.

This is *unusual* in a non-randomized, uncontrolled, 1-year observational study on a highly restricted sample:

<ul style="margin-top: 0; margin-bottom: 0; line-height: 0.9;">
  <li>No causal inference can be made from this study design</li>
  <li>It's done on univariable, unadjusted models</li>
  <li>They use Bayes factors to imply (strongly) the [absence of effect, not just lack of evidence](https://orca.cardiff.ac.uk/id/eprint/163206/4/tendeiro-et-al-2024-diagnosing-the-misuse-of-the-bayes-factor-in-applied-research.pdf#page=6&search=Presence%20versus%20absence)</li>
</ul>

This is a misuse of Bayesian inference; to "add credence" to a claim of no effect, based on an uncontrolled study design and simplistic modeling.

---

## 4 Bayesian Prior Choice {.smaller}


> “Bayes factors were calculated … using an ~ **rscale = 0.8** value of 0.8 to contrast a moderately informative prior with a conservative distribution width (to allow for potential large effect sizes”

Bayes factors compare how well the data are predicted under H₀ vs. H₁ — but H₁ isn’t just any nonzero effect; it's a distribution of plausible effect sizes defined by the prior.

The authors used a wide, Cauchy-like prior (r = 0.8), "due to the well-documented association between ApoB changes and coronary plaque changes."

- The model expected large effects from ApoB, so small effects could be seen as evidence for no effect.

This choice of prior isn't wrong, it is fragile, subjective, and drives the result.

<div style="font-size: 60%;">

["a researcher can have a very strong opinion about the model parameter values, and this opinion (via the prior) can drive the final model estimates."](https://www.frontiersin.org/journals/psychology/articles/10.3389/fpsyg.2020.608045/full)

["it is always important to conduct a prior **sensitivity analysis** to fully understand the influence that the prior settings have on posterior estimates"](https://www.nature.com/articles/s43586-020-00001-2)
</div>

---

## 5 Bayes Factor Interpretation {.smaller}

>"In other words, these data suggest it is 6 to 10 times more likely that the hypothesis of no association between these variables (the null) is true as
compared to the alternative."

[That is a overstatement of what the Bayes Factor tells us.](https://lakens.github.io/statistical_inferences/04-bayes.html#:~:text=One%20might%20therefore%20believe%20that%20Bayes%20factors%20tell%20us%20something%20about%20the%20probability%20that%20a%20hypothesis%20true%2C%20but%20this%20is%20incorrect.)

A Bayes factor of 6–10 means the **data** are 6–10× more likely under the **null model** than under the **alternative model**, not that the *null hypothesis is 6–10×* more likely to be true.

They *could* have said: "The data are 6–10 times more likely under the no-association model than under the alternative"

$$
\text{Posterior Odds} = \text{Bayes Factor} \times \text{Prior Odds}
$$

To claim that the null is 6–10× more likely to be *true*, they would have to assume **prior odds = 1:1** — and state that explicitly. They didn’t.

<small>Source: [Bayes Factors – Kass Raferty, 1995](https://www.nbi.dk/~koskinen/Teaching/AdvancedMethodsInAppliedStatistics2018/StudentPresentations/Bayes_factors_Jonas_S_Juul.pdf)</small>


## 5 Bayes Factor Interpretation {.smaller}

Even without other issues (e.g. confounding / non-adjusted variables / short follow-up / non-RCT, etc.),
the reported BF of **6.3 for ΔNCPV ~ ApoB** reflects only moderate evidence for no effect —
not strong or decisive.


<img src="assets/BF_interpretation.png" width="40%" style="display: block; margin: auto;" />

<div style="font-size: 60%; text-align: center; margin-top: 0.5em;">
<strong>Table 1.</strong> A heuristic classification scheme for Bayes factors <strong>BF<sub>10</sub></strong> 
Source: <a href="https://link.springer.com/content/pdf/10.3758/s13428-018-01189-8.pdf">SpringerLink</a>
</div>



<small>
(Assuming BF₁₀ as per standard conventions; if BF₀₁, it reverses)
</small>

---

## Summary {.smaller}

<div style="font-size: 85%; line-height: 1.2;">

1. **ΔNCPV as outcome**  
   Regressed (NCPV₁ − NCPV₀) on baseline NCPV₀ <br>
   Mathematical coupling → regression slopes reflect **algebra, not just biology**

2. **Univariable regressions**  
   Each predictor tested separately (ApoB, LDL-C, age…)  
   No confounder adjustment → **biased, unreliable, low credibility estimates**

3. **Bayesian inference**  
   Bayes inference used to support "no ApoB effect" & "plaque begets plaque"<br> 
   Unadjusted, observational data → **misleading, unusual use of Bayesian inference**

4. **Prior choice (rscale = 0.8)**  
   Prior assumes large effects<br>
   No sensitivity analysis → results likely **prior-driven**

5. **Bayes factor interpretation**  
   Claimed null is "6–10× more likely"<br>
   Bayes factor misstated as posterior probability → compares model fit, **not truth**

6. **Headline claim**  
   "Plaque Begets Plaque, ApoB Does Not"<br>
   Overstates evidence → **mathematically coupled, confounded, and fragile analysis**

</div>

---

"Plaque Begets Plaque, ApoB Does Not"

<br>
The study regressed mathematically coupled differences in plaque volume (ΔNCPV) on baseline variables using univariable models, then made the unusual choice to use Bayesian inference (also without accounting for confounding), applied a prior without reporting a sensitivity analysis (which the strength of the Bayes Factor likely hinges on), and interpreted the Bayes Factors as evidence for no ApoB effect, culminating in a headline that far exceeds what the statistical methods can credibly support.


# Additional Concerns

---

## No Adjustment for Multiple Comparisons {.smaller}

Predictors tested against **two** outcomes (Δ-NCPV, Δ-TPS) → ≥10 comparisons

* Bonferroni: α = 0.05 → α′ ≈ 0.005  
  Baseline CAC (P < 0.001) would survive; others might not  
* Benjamini–Hochberg FDR maintains power with correlated tests

Numerous regressions were run — increasing **false positive risk**  
But no multiple testing correction was applied.

Perhaps the authors viewed this as exploratory, where correction is often skipped —  
**but then why title the paper "Plaque Begets Plaque, ApoB Does Not"?**

---

## Zero-inflation, censoring, heteroscedasticity {.smaller}

<div style="font-size: 80%;">
Baseline NCPV median = 44 mm³; **TPS median = 0** → ≥50% of values are zero  
CCTA cannot report negative plaque → both outcomes are **left-censored at 0**

This affects not just modeling but measurement:  
When true plaque ≈ 0, **error is asymmetric** — it can only overestimate.

ΔNCPV, their primary outcome, is a change score between two bounded, skewed measures.  
Likely to produce **non-normal residuals** and **heteroscedasticity** (e.g., larger spread at higher baseline).

> If smaller baseline values were also linked to larger increases,  
> this may reflect the effects of left-censoring and error asymmetry — not true biological acceleration.

These issues are **clear in TPS**, and may affect NCPV, but diagnostics are not shown.

*OLS assumes homoscedastic, normal residuals*  
*performance::check_model() was run — but no output provided*

They could have considered methods to address this such as: **Tobit regression**, **log-transform**, or **robust SEs**

</div>